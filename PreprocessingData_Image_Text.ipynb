{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PreprocessingData_Image_Text.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/SwapnilSParkhe/Image-Caption-Generation/blob/master/PreprocessingData_Image_Text.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "8FqIguZ2ZDWd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Preparing Data for Image and Text"
      ]
    },
    {
      "metadata": {
        "id": "IhBfDLf5ZDWf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Image Data"
      ]
    },
    {
      "metadata": {
        "id": "XdVILg-YZDWg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Getting data**"
      ]
    },
    {
      "metadata": {
        "id": "vaO1vs0waGIP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "30f5e98b-1b92-41ce-a277-1cc15fc0eb64"
      },
      "cell_type": "code",
      "source": [
        "#Getting the data from the web\n",
        "!wget http://nlp.cs.illinois.edu/HockenmaierGroup/Framing_Image_Description/Flickr8k_Dataset.zip -P drive/app\n",
        "\n",
        "#Unzipping the data\n",
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('Flickr8k_Dataset.zip', 'r')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-04-14 23:34:16--  http://nlp.cs.illinois.edu/HockenmaierGroup/Framing_Image_Description/Flickr8k_Dataset.zip\r\n",
            "Resolving nlp.cs.illinois.edu (nlp.cs.illinois.edu)... 192.17.58.132\r\n",
            "Connecting to nlp.cs.illinois.edu (nlp.cs.illinois.edu)|192.17.58.132|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115419746 (1.0G) [application/zip]\n",
            "Saving to: ‘drive/app/Flickr8k_Dataset.zip’\n",
            "\n",
            "Flickr8k_Dataset.zi 100%[===================>]   1.04G  56.1MB/s    in 15s     \n",
            "\n",
            "2018-04-14 23:34:32 (69.0 MB/s) - ‘drive/app/Flickr8k_Dataset.zip’ saved [1115419746/1115419746]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-QPL4h0ShMgE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Importing relevant libraries**"
      ]
    },
    {
      "metadata": {
        "id": "zpqPvrnBZDWh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from os import listdir   #Lists all names in a given directory's path\n",
        "from keras.applications.vgg16 import VGG16   #VGG16 model's weights to extract features of images from last layer\n",
        "from keras.preprocessing.image import load_img   #Load an image to a target PIL (Python Imaging Library) image\n",
        "from keras.preprocessing.image import img_to_array   #Converts PIL image to an array\n",
        "from keras.applications.vgg16 import preprocess_input, decode_predictions \n",
        "from keras.models import Model\n",
        "from pickle import dump   #Save outputs to a pickle file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s57F2b45ZDWp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Extracting features of image(s) in our directory and saving to a file**"
      ]
    },
    {
      "metadata": {
        "id": "96MF4Jc3ZDWq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1054
        },
        "outputId": "051cdc35-6eff-44b9-ae20-90b55b6fb3cc"
      },
      "cell_type": "code",
      "source": [
        "#A function to extract features of images in a directory (Using VGG16 here)\n",
        "def ImageFeature_Extractor(ImageDirectory):    \n",
        "    #Loading the model\n",
        "    model=VGG16(weights=\"imagenet\")\n",
        "\n",
        "    #Restructing the model (removing the last softmax classification layer so as to retain the penultimate FCC-4096)\n",
        "    model.layers.pop()\n",
        "    model=Model(inputs=model.inputs, outputs=model.layers[-1].output)\n",
        "\n",
        "    #Summarizing our re-structured model\n",
        "    print(model.summary())\n",
        "\n",
        "    #Extracting features from each image (jpg) from our image directory (present in work directory)   \n",
        "    features=dict()\n",
        "    for ImageName in listdir(ImageDirectory):   #accessing elements of our ImageDirectory\n",
        "        image_file_name=ImageDirectory + '/' + ImageName   #accessing the Image files in our directory  \n",
        "        image=load_img(image_file_name,target_size=(224,224))   #loading each image to adhere with model inputs\n",
        "        image=img_to_array(image)   #converting PIL image to array\n",
        "        image=image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))   #to adhere with model inputs\n",
        "        image=preprocess_input(image)   #final preprocessing of image for our model\n",
        "        image_feature=model.predict(image,verbose=0)   #getting image features\n",
        "        image_id=ImageName.split('.')[0]   #getting the image_id as name of image before '.'\n",
        "        features[image_id]=image_feature   #mapping and storing image_features to image_id\n",
        "        if len(features)%1000==0:\n",
        "          print(\"No. of images processed\",len(features))\n",
        "    return features\n",
        "\n",
        "#Calling the above created function for our ImageDirectory\n",
        "features = ImageFeature_Extractor('Flicker8k_Dataset')\n",
        "print('Extracted Features: %d' % len(features))\n",
        "\n",
        "#Saving above extracted features to file (for future use)\n",
        "dump(features, open('features.pkl', 'wb'))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "=================================================================\n",
            "Total params: 134,260,544\n",
            "Trainable params: 134,260,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "No. of images processed 1000\n",
            "No. of images processed 2000\n",
            "No. of images processed 3000\n",
            "No. of images processed 4000\n",
            "No. of images processed 5000\n",
            "No. of images processed 6000\n",
            "No. of images processed 7000\n",
            "No. of images processed 8000\n",
            "Extracted Features: 8091\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iNwvfJrwZDW1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Text Data"
      ]
    },
    {
      "metadata": {
        "id": "KCbrjDHihbEN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Getting data**"
      ]
    },
    {
      "metadata": {
        "id": "Reyb72RNbW1q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "faab7384-9def-464c-db06-2c66d5784ab9"
      },
      "cell_type": "code",
      "source": [
        "#Getting the data from the web\n",
        "!wget http://nlp.cs.illinois.edu/HockenmaierGroup/Framing_Image_Description/Flickr8k_text.zip -P drive/app\n",
        "\n",
        "#Unzipping the data \n",
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('Flickr8k_text.zip', 'r')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-04-14 23:33:34--  http://nlp.cs.illinois.edu/HockenmaierGroup/Framing_Image_Description/Flickr8k_text.zip\n",
            "Resolving nlp.cs.illinois.edu (nlp.cs.illinois.edu)... 192.17.58.132\n",
            "Connecting to nlp.cs.illinois.edu (nlp.cs.illinois.edu)|192.17.58.132|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2340801 (2.2M) [application/zip]\n",
            "Saving to: ‘drive/app/Flickr8k_text.zip’\n",
            "\n",
            "Flickr8k_text.zip   100%[===================>]   2.23M  5.04MB/s    in 0.4s    \n",
            "\n",
            "2018-04-14 23:33:35 (5.04 MB/s) - ‘drive/app/Flickr8k_text.zip’ saved [2340801/2340801]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LhqCQJi_ZDW2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Preparing text data (Cleaning and manipulating)**"
      ]
    },
    {
      "metadata": {
        "id": "TCfrHzj0ZDW4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Imporitng: Loading and Reading text file (containing photo identifier and corresponding multiple descriptions)\n",
        "def import_file(input_file):\n",
        "    text_file=open(input_file,'r')   #creating a bridge btwn OS file and Py file for reading\n",
        "    text=text_file.read()   #reading from OS file to Py file\n",
        "    text_file.close()\n",
        "    return text\n",
        "\n",
        "imported_file=import_file('Flickr8k.token.txt')\n",
        "\n",
        "#Organising imported_file file so as to map image's ID and descriptions\n",
        "def organise_file(file):\n",
        "    mapping=dict()\n",
        "    for line in file.split('\\n'):   #accessing each line in doc spearated by '\\n'\n",
        "        tokens=line.split()   #tokenizing based on white spaces into image's ID and many desc based tokens\n",
        "        if len(line)<2:\n",
        "            continue\n",
        "        image_id, image_desc=tokens[0],tokens[1:]   #getting ID and desc for images\n",
        "        image_id=image_id.split('.')[0]   #removing \"jpg#_\" from image's filename\n",
        "        image_desc=' '.join(image_desc)   #creating desc string from tokens\n",
        "        if image_id not in mapping:   #creating a list of 5 desc for each new imageID \n",
        "            mapping[image_id]=list()\n",
        "        mapping[image_id].append(image_desc)   #appending desc for each same imageID\n",
        "    return mapping\n",
        "\n",
        "organised_file=organise_file(imported_file)\n",
        "\n",
        "#Cleaning data (lowercasing, retaining alphabetical words, removing punctuation, len(word)>1)\n",
        "import string\n",
        "def clean_desc(file):\n",
        "    table=str.maketrans('','',string.punctuation)\n",
        "    for key, desc_list in file.items():\n",
        "        for i in range(len(desc_list)):\n",
        "            desc=desc_list[i]   \n",
        "            desc=desc.split()   #tokenizing\n",
        "            desc=[word.lower() for word in desc]   #lowercasing\n",
        "            desc=[word for word in desc if word.isalpha()]   #retaining alphabetical words\n",
        "            desc=[w.translate(table) for w in desc]   #removing punctuation\n",
        "            desc=[word for word in desc if len(word)>1]   #removing single letters like 's' or 'a'\n",
        "            desc_list[i]=' '.join(desc)   #replacing original and storing cleaned version of text\n",
        "    return file\n",
        "\n",
        "cln_orgnse_text=clean_desc(organised_file)\n",
        "\n",
        "#Exporting: save desc to file, one per line\n",
        "def export_file(output_file, filename):\n",
        "    lines = list()\n",
        "    for key, desc_list in output_file.items():\n",
        "        for desc in desc_list:\n",
        "            lines.append(key + ' ' + desc)   #for same key, appending desc (for all keys) as lines\n",
        "    data = '\\n'.join(lines)   #storing lines separated by '/n'\n",
        "    file = open(filename, 'w')   #creating a bridge between Py and OS for writing\n",
        "    file.write(data)   #writing data to Py file and thus OS file\n",
        "    file.close()\n",
        "\n",
        "export_file(cln_orgnse_text, 'cln_orgnse_text.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}